{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "everything's loaded\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "train = datasets.MNIST('', train=True, download=True,\n",
    "                      transform=transforms.Compose([\n",
    "                          transforms.ToTensor()\n",
    "                      ]))\n",
    "test = datasets.MNIST('', train=False, download=True,\n",
    "                      transform=transforms.Compose([\n",
    "                          transforms.ToTensor()\n",
    "                      ]))\n",
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=False)\n",
    "print(\"everything's loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# a few new imports\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# the above are similar, nn is just instantiable\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # defining the fully connect to the layers to the network\n",
    "        self.fc1 = nn.Linear(28*28, 64) # input is the images, output is 3 layers of 64 neurons of layers, nn.Linear is a flattened vector\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10) # takes in 64, but outputs 1-10\n",
    "\n",
    "    def forward(self, x):  # defines how the data flow through our network\n",
    "        x = F.relu(self.fc1(x)) # rectified linear over an entire layer; the activation function; whether or not the brain is firing\n",
    "        x = F.relu(self.fc2(x)) # you can actually put logic, i.e. if statements\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)  # this is a probability distribution for numbers 0-9\n",
    "        return F.log_softmax(x, dim=1) # applies to output layer, \"what is the probability distribution that we want to sum to 1\"\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand((28,28))\n",
    "X = X.view(-1, 28*28) # -1 just specifies it is an unknown shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.2087, -2.3450, -2.2651, -2.3284, -2.2499, -2.3687, -2.2680, -2.2910,\n",
       "         -2.4151, -2.3028]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1116, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0131, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0160, grad_fn=<NllLossBackward>)\n",
      "okay\n"
     ]
    }
   ],
   "source": [
    "# loss: how long is the model? we want it to be 100% confident\n",
    "# optimizer: adjusts the weights in order to minimize the loss\n",
    "import torch.optim as optim\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)  # learning rate: the size of the step, optimally you have a decaying learning rate\n",
    "EPOCHS = 3 # a full passthrough of our data\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for data in trainset:\n",
    "        # data is a batch of featuresets and labels\n",
    "        X, y = data\n",
    "        # everytime we calculate loss and optimize the model\n",
    "        net.zero_grad()  # when you can only pass one set of features/labels at a time, but you get the benefit of batch training\n",
    "        output = net(X.view(-1, 28*28))\n",
    "        # we can calculate how wrong were we\n",
    "        loss = F.nll_loss(output, y)\n",
    "        # two ways to calculate loss, \"one hot vector\" i.e. [0, 1, 0, 0, 0, 0, 0,0], \n",
    "        # if your data is a scalar value, use nll_loss, if your data is a 1 hot vector, use MSE\n",
    "        # back propogation:\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss)\n",
    "print(\"okay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.991\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testset:\n",
    "        X, y = data\n",
    "        output = net(X.view(-1, 784))\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "print(\"Accuracy: \", round(correct/total, 3))\n",
    "# My computer is super slow, still cannot see loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X[7].view(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5)\n"
     ]
    }
   ],
   "source": [
    "# for predicting\n",
    "print(torch.argmax(net(X[7].view(-1, 784))[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
